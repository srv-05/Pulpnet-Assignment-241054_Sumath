{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha5Iyjnp4Tol"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/movie.csv')"
      ],
      "metadata": {
        "id": "t14sKOaS4n8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "M1NrzrBi45KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "_qD5jsCo47HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "v2hqidDH4_p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ehVPEIex5G1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "8KTBNFkU5I-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "4vy_vAik49Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "4H68ybkU5Omi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop_duplicates()"
      ],
      "metadata": {
        "id": "rYT2-aET5moD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].unique()"
      ],
      "metadata": {
        "id": "2zVv666V5x7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='label', data=df)\n",
        "\n",
        "plt.title('Distribution of Positive and Negative Reviews')\n",
        "plt.xlabel('Label (0 = Negative, 1 = Positive)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BXkd8xVZ778l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Pre-Processing"
      ],
      "metadata": {
        "id": "MXhvsLj08geW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to lower case"
      ],
      "metadata": {
        "id": "GjwD8hK3-R6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['lower_text']=df['text'].str.lower()"
      ],
      "metadata": {
        "id": "GWSk2zK78VVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove special charectars and emoji"
      ],
      "metadata": {
        "id": "FKVPqcgv-Tvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['removed_text'] = df['lower_text'].astype(str).str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
        "df['removed_text'] = df['lower_text'].str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)"
      ],
      "metadata": {
        "id": "zIUhNG-B9Ksf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization using nltk"
      ],
      "metadata": {
        "id": "9o0RL0r1LAH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokens']=df['removed_text'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "_zimyCSrLC09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "d-ZqJR-LAUT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()\n",
        "df['stemming']=df['tokens'].apply(lambda x: [stemmer.stem(y) for y in x])"
      ],
      "metadata": {
        "id": "OG8BgI2NAVgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lametization"
      ],
      "metadata": {
        "id": "cZAUM9XIDKcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')\n",
        "df['lametization']=df['tokens'].apply(lambda x: [nlp(y)[0].lemma_ for y in x])"
      ],
      "metadata": {
        "id": "k6Q196e2DL97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization using Tensorflow"
      ],
      "metadata": {
        "id": "uLV2HdUr-YyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(df['removed_text'])\n",
        "df['sequences'] = tokenizer.texts_to_sequences(df['removed_text'])"
      ],
      "metadata": {
        "id": "2alLoXBY9QQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joining tokens"
      ],
      "metadata": {
        "id": "yBnZ0s1KjCPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['joined_stemming_tokens'] = df['stemming'].apply(lambda y: ' '.join(y))"
      ],
      "metadata": {
        "id": "q9PPlFozjb-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['joined_lammetization_tokens'] = df['lametization'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "YILsNZthjElr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test/Train Split"
      ],
      "metadata": {
        "id": "cT94wPB7FdG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['joined_stemming_tokens']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9Or6Xf08FfJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction\n"
      ],
      "metadata": {
        "id": "plD9bbyCbcUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One Hot Encoding"
      ],
      "metadata": {
        "id": "r58jcQYJbnQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer1 = CountVectorizer(binary=True)\n",
        "X = vectorizer1.fit_transform(df['joined_stemming_tokens'])\n",
        "##one_hot_df_s = pd.DataFrame(X.toarray(), columns=vectorizer1.get_feature_names_out())"
      ],
      "metadata": {
        "id": "zWpLH6xXbe-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2 = CountVectorizer(binary=True)\n",
        "Y = vectorizer2.fit_transform(df['joined_lammetization_tokens'])\n",
        "one_hot_df_l = pd.DataFrame(Y.toarray(), columns=vectorizer2.get_feature_names_out())"
      ],
      "metadata": {
        "id": "xYT9Gs7dlmjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words"
      ],
      "metadata": {
        "id": "jfbhJj4gbpoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer3 = CountVectorizer()\n",
        "X_bow = vectorizer3.fit_transform(df['joined_stemming_tokens'])\n",
        "##bow_df_s = pd.DataFrame(X_bow.toarray(), columns=vectorizer3.get_feature_names_out())"
      ],
      "metadata": {
        "id": "5LB6414PkvGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer4 = CountVectorizer()\n",
        "Y_bow = vectorizer4.fit_transform(df['joined_lammetization_tokens'])\n",
        "bow_df_l = pd.DataFrame(Y_bow.toarray(), columns=vectorizer4.get_feature_names_out())"
      ],
      "metadata": {
        "id": "uyJQKayvlvMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf-Idf"
      ],
      "metadata": {
        "id": "BvbkL9H4lGvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "XH_qRNm6lJw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer1 = TfidfVectorizer()\n",
        "Y_tfidf = tfidf_vectorizer1.fit_transform(df['joined_lammetization_tokens'])\n",
        "tfidf_df_l = pd.DataFrame(Y_tfidf.toarray(), columns=tfidf_vectorizer1.get_feature_names_out())"
      ],
      "metadata": {
        "id": "1C00vAF7mAHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorizer"
      ],
      "metadata": {
        "id": "5gIzSBmsxv36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(binary=True)\n",
        "X_train_bin = vectorizer.fit_transform(X_train)\n",
        "X_test_bin = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "O6tkaU3exxQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "UfWjP67bx67k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)\n",
        "y_pred = model.predict(X_test_vec)\n",
        "y_pred_prob = model.predict_proba(X_test_vec)[:, 1]"
      ],
      "metadata": {
        "id": "iPShzleex9Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score"
      ],
      "metadata": {
        "id": "D0lD9ZGp3g_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Score:\", acc)"
      ],
      "metadata": {
        "id": "DOIzKGzjz2nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 Score"
      ],
      "metadata": {
        "id": "tFoKM4pW3jKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "FyuA2_6U3k5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC-AUC Score"
      ],
      "metadata": {
        "id": "h5ltVq0p3t4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(\"ROC-AUC Score:\", roc)"
      ],
      "metadata": {
        "id": "66E8Tky03wGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "j2IXYiMI4MG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "4t2Wu_2V4OZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bernoulli Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "Qqleo6kAz6IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train_bin, y_train)\n",
        "y_pred0 = bnb.predict(X_test_bin)\n",
        "y_pred_prob0 = bnb.predict_proba(X_test_bin)[:, 1]"
      ],
      "metadata": {
        "id": "BpY4_0q9z8q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score"
      ],
      "metadata": {
        "id": "Ui3Se4So5JIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac = accuracy_score(y_test, y_pred0)\n",
        "print(\"Accuracy Score:\", acc)"
      ],
      "metadata": {
        "id": "-Ye1z-Q15P4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 Score"
      ],
      "metadata": {
        "id": "poYoO0a96W4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(y_test, y_pred0)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "kixbD4-u6ZwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC-AUC Score"
      ],
      "metadata": {
        "id": "2J7tU9pO6edz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc = roc_auc_score(y_test, y_pred_prob0)\n",
        "print(\"ROC-AUC Score:\", roc)"
      ],
      "metadata": {
        "id": "ljoRdYI66hoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "kJ90Wujw6rFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred0)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "BUnbT5hJ6tFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM (Support Vector Machine)"
      ],
      "metadata": {
        "id": "FaXxlncE0Wp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train_vec, y_train)\n",
        "y_pred1 = svm.predict(X_test_vec)\n",
        "y_pred_prob1 = svm.predict_proba(X_test_vec)[:, 1]"
      ],
      "metadata": {
        "id": "4W8phzNu0ZCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score"
      ],
      "metadata": {
        "id": "JoXgziAw7VSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_test, y_pred1)\n",
        "print(\"Accuracy Score:\", acc)"
      ],
      "metadata": {
        "id": "nRanDm5h7XEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 Score"
      ],
      "metadata": {
        "id": "WIL-UD4t7lfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(y_test, y_pred1)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "Ez0j17a57nw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC-AUC Score"
      ],
      "metadata": {
        "id": "gvSI_pGp7p1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc = roc_auc_score(y_test, y_pred_prob1)\n",
        "print(\"ROC-AUC Score:\", roc)"
      ],
      "metadata": {
        "id": "RyIk2x-w7sF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "q8R4UOmt7umT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred1)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "g1KBpJ4B7wcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "S87XDh8w2NYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "5OSawclh2QeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred7 = rf_model.predict(X_test_vec)\n",
        "y_pred_prob7 = rf_model.predict_proba(X_test_vec)[:, 1]"
      ],
      "metadata": {
        "id": "myjNqjHi2bxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score"
      ],
      "metadata": {
        "id": "MwarGik0CbT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred7)\n",
        "print(\"Accuracy Score: \",accuracy)"
      ],
      "metadata": {
        "id": "IjbP0rKaCcek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 Score"
      ],
      "metadata": {
        "id": "-xGfYSyeCmcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(y_test, y_pred7)\n",
        "print(\"F1 Score: \", f1)"
      ],
      "metadata": {
        "id": "SId4WamiCn8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC-AUC Score"
      ],
      "metadata": {
        "id": "k6qD1HuXCvsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc = roc_auc_score(y_test, y_pred_prob7)\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")"
      ],
      "metadata": {
        "id": "9huqwVLACx49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix"
      ],
      "metadata": {
        "id": "gmdHirLuDE-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred7)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "-MLXFR-XDHEM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}